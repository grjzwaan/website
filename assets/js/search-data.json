{
  
    
        "post0": {
            "title": "Popularity as a flawed proxy",
            "content": "Python is the most popular programming language for machine learning. So sayeth the internet… So you should pick Python to learn over other languages. But, is it? Should you? . Bla bla bla . Most of these articles have no basis and combine some opinions on how Python code is clean, it’s popular (notice the circular reference?) and that it has many libraries. Every update of an index (for example TIOBE) spawns derivative articles how Python went up a notch, or Julia is posed to overtake it. . I think it’s good to take a step back and ask yourself: . How did they measure popularity? | Is this representative for my field? | Do I actually care about popularity? | . The aforementioned TIOBE index takes the number of results in search engines as input. Seems reasonable, but more is not always better. In my bubble you sometimes think that everyone has a blog, but there is a big world of enterprise software. In this setting there is less blogging and tweeting, but there are great engineers. . Fundamentals, not popularity . Popularity might seem like a good proxy to choose a language to learn, but it’s hard to gauge the real popularity. There are many echo chambers/bubles in which the gospel of X is spread. . I argue that you should go fundamentals first. Yes, being fluid in a language helps, but being shitty at the basics results in shitty code. Enjoying the coding is also important, so if you enjoy Julia, R, Java or Swift more than Python: by all means, start with that. . The future . Many reasons that these articles mention why Python is great might be moot. Pretty soon we’ll get compiler infrastructure for GPU’s and all the hand-tuned libraries in Pytorch and Keras will be available for all languages that target LLVM (even Python does this through Numba). . Swift allows you to mix Python code into your Swift project, so you don’t even need to choose. . So pick Python because it’s fun, beautiful or convenient because a great course on ML is using it. Learn fundamentals. Then, also learn other languages a little to understand the differences. . CV . All advice above is moot for applying for jobs. For this I would actually advice to learn all popular tools and have sample projets. You know what the recruiter/HR will ask ;) .",
            "url": "https://grjzwaan.github.io/website/2020/07/31/popularity-as-a-flawed-proxy.html",
            "relUrl": "/2020/07/31/popularity-as-a-flawed-proxy.html",
            "date": " • Jul 31, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Python vs Javascript for neural networks",
            "content": "In this article I describe why I would prefer Python to JavaScript specifically for neural networks. . This post is only based on actual features of the language and its design, not hand waving of ‘popularity’. Both Python and JavaScript are general programming languages. Both can accomplish any task and probably in comparable speed. So let’s focus on the specific domain: neural networks. . Through some simple programs you can see why Python could be appealing. This is based on my observations to program auto differentiation in JavaScript. . The conclusions could be extended to other machine learning techniques. This is left as an exercise for the reader™. . The Premise . Programming languages bridge the gap between the real world and computers. Through the language we encode our ideas and hope it works as expected. If the code resembles how we think about a topic it makes it much easier. For example, anything can be made unintuitive if programmed in assembly. For many domains there are domain specific languages. Either full-blown programming languages or embedded. Haskell and Swift are particularly great at this. . This will be the biggest difference between Python and JavaScript. Python is quite amenable to this process, and JavaScript is not - for logical historical reasons, I might add. . Auto differentiation . Auto differentiation is a core component of neural networks and how to build them efficiently. To perform back propagation you need to (approximately) calculate the gradient. . The language of differentiation is functions and mathematical operations. For example $f(x)=(x+6)*7$. All operations in neural networks are basic mathematical operations, most on tensors. Let’s write code to represent a function in Python and Javascript. . Operator overloading . In both languages we want an object of a class Value that represents the function for a particular input. As a building block we need to write down the computations we want to do. Visually the Python code looks nicer. . Python: . x = Value(5) y = (x + 6) * 7 . In the code above y is actually a Value! Furthermore, we get the whole computation tree of intermediate values. . JavaScript: . let x = new Value(5) let y = mult(add(x, 6, 7)) . This is because Python allows us to extend arithmetic on objects with custom functions by defining __add__ on the object as follows: . class Value: def __init__(self, x, _deps=[]): self.data = x def __add__(self, other): other = other if isinstance(other, Value) else Value(other) return Value(self.data + other.data, _deps=[self, other]) def __mul__(self, other): other = other if isinstance(other, Value) else Value(other) return Value(self.data * other.data, _deps=[self, other]) def __radd__(self, other): return self + other def __rmul__(self, other): return self * other . Objects as functions . Every neuron in the neural network consists of weights, biases and an activation function: . neuron(input) = relu(weight * input + bias) . In most approaches to perform back-propagation its handy to also have some mutable state in the neuron. So it’s both a function and an object. . In Python we can use an object as a function which results in this code: . neuron = Neuron(5) output = neuron([1,2,3,4,5]) . For JavaScript we would need to . let neuron = Neuron(5) let output = neuron.eval([1,2,3,4,5]) . List comprehensions . List comprehensions and generators are two features of Python that I really miss in other languages. . In Python we can multiply two arrays A and B by doing: . result = [a*b for a,b in zip(A, B)] . In JavaScript you would need to do implement the zip function and do: . result = zip(A, B).forEach(t =&gt; t[0]*t[1]) . However, the zip function actively constructs the array of tuples instead of lazily generating it during the iteration. JavaScript actually supports generators but it requires more coding, because there is no natural way to map over them: . function* zip(A, B) { let i = 0; while(i &lt; Math.min(A.length, B.length) ) { yield [A[i], B[i]]; i++; } return [A[i], B[i]]; } let result = []; for(let t of zip(A, B)) { result.push(t[0] * t[1]) } . Wrap-up . Obviously you can build neural networks in JavaScript. I hope that through these examples you see how much closer to reality you can get in Python and why people would prefer it. . However, there is a small downside to the Python code: to a beginner it appears as magical and it’s harder to find the place where the code is defined. For JavaScript it’s explicit. .",
            "url": "https://grjzwaan.github.io/website/2020/07/13/python-vs-javascript.html",
            "relUrl": "/2020/07/13/python-vs-javascript.html",
            "date": " • Jul 13, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Scaffolding in Eleventy",
            "content": "I’ve rebuild my website with Elventy and Tailwind. One feature that I really liked about Hugo was to scaffold new posts, so I’ve build my own Steiger. . All of my blogs have been static sites that are generated in a build process and then pushed to some hosting. Each post is simply a markdown page in the folder denoting it’s date, so posts/2020/07/06/scaffolding-in-eleventy.md for this particular post. Each page also has metadata for the title, description, etc… . title: &quot;Scaffolding in Eleventy&quot; description: &quot;Scaffolding in Eleventy&quot; date: 2020-07-06T16:27:46.409+02:00 draft: false tags: [Elventy, static website] . With these things I’m really lazy. I do not want to copy/paste, create folders, etc. Just execute scaffold posts/2020/07/06/scaffolding-in-eleventy.md and I want to have a premade template where I fill in the content. . Unfortunately it was not included in Eleventy, so I rolled my own using Chalk for colored terminal output, Commander for the CLI, Luxon for dates, times (because the vanilla dates in Javascript breaks your brain), Nunjucks for templating. . The package has reached version 0.0.2 and it autogenerates the file you want, checks if it exists and gives the current datetime to the template. Over time as I use it, I’ll probably add more features. .",
            "url": "https://grjzwaan.github.io/website/2020/07/06/scaffolding-in-eleventy.html",
            "relUrl": "/2020/07/06/scaffolding-in-eleventy.html",
            "date": " • Jul 6, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Building Autodiff from Scratch",
            "content": "I’ve made an interactive notebook with Observable to show how you can implement autodifferentiation from scratch. .",
            "url": "https://grjzwaan.github.io/website/2020/07/06/building-autodiff-from-scratch.html",
            "relUrl": "/2020/07/06/building-autodiff-from-scratch.html",
            "date": " • Jul 6, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Inject Context",
            "content": "This is a small post on how to inject services/contexts into functions. . The motivating example is working with databases and sessions in a webservice. Each call you create a database session, do your stuff, and close the session. When everything goes right, commit. On errors it need to rollback. . Luckily Python has a nice feature called context managers that you can use with a with statement: . # POST /cats/{cat_id:int} def route(request): # Get the parameters and information from the form description = request.form().get(&#39;description&#39;, None) cat_id = request.path_params[&#39;cat_id&#39;] # Open a session and query the database with db.session() as session: cat = session.query(model.Cats).filter(model.Cats.id == cat_id).first() if cat is None or description is None: raise Exception(&quot;Need more information&quot;) cat.description = description session.commit() # An ORM like SQLAlchemy automatically flushes the changes of cat to the database . This gets tedious when a lot or your routes have this piece of code. Some web frameworks allow ‘middleware’ and you could inject the session there…but now every route opens a session with your database: that seems overkill. (But hopefully you or your library uses a connection pool). . Premature optimization is the root of fun and evil, so it’ll be interesting to see how the code looks like. . Our goal will be to get the following form: . # POST /cats/{cat_id:int} def route(request, db_session): description = request.form().get(&#39;description&#39;, None) cat_id = request.path_params[&#39;cat_id&#39;] cat = db_session.query(model.Cats).filter(model.Cats.id == cat_id).first() if description is None or cat is None: throw Exception(&quot;Need more info!&quot;) cat.description = description . We introduce a Depends class that wraps around a context manager and is declared as default parameter. In Python default parameter values are evaluated when the function is defined, so the Depends wrapper will later give us the session context manager. To change the function we’ll use a decorator automagic that will inject this new functionality. . # POST /cats/{cat_id:int} @automagic def route(request: Request, db_session: DBSession = Depends(db.session()), ): description = request.form().get(&#39;description&#39;, None) cat_id = request.path_params[&#39;cat_id&#39;] cat = db_session.query(model.Cats).filter(model.Cats.id == cat_id).first() if description is None or cat is None: throw Exception(&quot;Need more info!&quot;) cat.description = description . Alternative . The alternative is to make a simpler decorator that injects the session in a pre-determined keyword like this: . @inject_db_session def route(request: Request, db_session: DBSession), ): description = request.form().get(&#39;description&#39;, None) cat_id = request.path_params[&#39;cat_id&#39;] cat = db_session.query(model.Cats).filter(model.Cats.id == cat_id).first() if description is None or cat is None: throw Exception(&quot;Need more info!&quot;) cat.description = description . The decorator is much easier to write: . from functools import wraps def inject_db_session(func): @wraps(func) def wrapped(*args, **kwargs): return func(*args, **{**kwargs, db_session}) return wrapped . It has several features of interest though: . It uses functools.wraps. This ensures that the name and the documentation of the wrapped function stay inplace. See this excellent Stackoverflow answer. | It combines the named arguments **kwargs with the new keyword in such a way that the new db_session supersedes the case when the function would be called with the same keyword. | . The code . Below you can see the code that I wrote for this and it works with an arbitrary number of Depends. . The followup question is of course: . Can we also get rid of the boilerplate for getting a path parameter and formdata? For a request endpoint most of the information should come from path parameters and the form (i.e. the body of the request). . Here we have the following assumptions: . We will use Pydantic to parse the formdata. | Depends parameters are replaced with their context managers; | Simple (int, str, …) arguments are replace by path parameters according to name; | Pydantic model arguments are used to parse the form data. Errors are handled by the automagic. You can have at most one of these models. | . It’ll look like this: . # POST /cats/{cat_id:int} @automagic def route(request: Request, cat_id: int, catUpdateRequest: CatUpdateRequest, db_session: DBSession = Depends(db.session()), ): cat = db_session.query(model.Cats).filter(model.Cats.id == cat_id).first() if cat is None: throw HTTPException(404, &quot;Give a valid cat id&quot;) cat.description = catUpdateRequest.description . This is also the route that FastAPI took to create their routes. However, I don’t know about the implementation. Funnily I found this framework because I wanted the above functionality, made a prototype and Googled it later. . Let’s first define some mock objects: . from typing import Callable, List from contextlib import contextmanager, ExitStack import inspect import pydantic from functools import wraps class DBSession: &quot;&quot;&quot; A mock DBSession class that has the most important functions of a session with a database. &quot;&quot;&quot; def query(self, needle, haystack): return f&quot;Finding {needle} in {haystack}: {needle in haystack}&quot; def commit(self): pass def rollback(self): pass def close(self): pass class Database: &quot;&quot;&quot; A mock Database class that can create a session scope (this is similar to how it would work with SQLAlchemy). &quot;&quot;&quot; def __init__(self, url): # Do some initialization self.url = url def connect(self): pass def disconnect(self): pass def create_session(self): return DBSession() @contextmanager def session_scope(self): session = self.create_session() try: print(f&quot;Create session for database {self.url}&quot;) yield session session.commit() except: session.rollback() raise finally: print(f&quot;Close session for database {self.url}&quot;) session.close() . Now we write our Depends wrapper: . class Depends: &quot;&quot;&quot; Small wrapper to be able to determine which resources &quot;&quot;&quot; def __init__(self, c: Callable): self.c = c def __call__(self): return self.c . Now the good stuff, the automagic function: . def automagic(f): # Get the signature and extract dependencies and the formdata signature = inspect.signature(f) dependencies = {n: p.default for n, p in signature.parameters.items() if p.default.__class__ == Depends} form_name, form_class = next(((n, p.annotation) for n, p in signature.parameters.items() if issubclass(p.annotation, pydantic.BaseModel)), None) # Create the wrapped function, construct the context managers and inject the information @wraps(f) def wrapped(*args, **kwargs): form = {} if form_name: form = {form_name: form_class(**request[&#39;form_data&#39;])} with ExitStack() as stack: resources = {} for name, resource in dependencies.items(): res = stack.enter_context(resource()) resources[name] = res f(*args, **{**kwargs, **request[&#39;path_params&#39;], **resources, **form}) return wrapped . Finally using all these goodies: . db1 = Database(&quot;localhost:666/beast&quot;) db2 = Database(&quot;localhost:42/answers&quot;) class Form(pydantic.BaseModel): answer: int answers: List[int] @automagic def sample_route( request, neighbour: int, form: Form, s1=Depends(db1.session_scope()), s2=Depends(db2.session_scope())): print(f&quot;Query: {s1.query(neighbour, [665, 667])}&quot;) print(f&quot;Query: {s2.query(form.answer, [42])}&quot;) print(&quot;I know all the answers now!&quot;) request = { &#39;path_params&#39;: { &#39;neighbour&#39;: 667 }, &#39;form_data&#39;: { &#39;answer&#39;: 43, &#39;answers&#39;: [&#39;42&#39;] } } sample_route(request) .",
            "url": "https://grjzwaan.github.io/website/2020/03/17/inject-context.html",
            "relUrl": "/2020/03/17/inject-context.html",
            "date": " • Mar 17, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Clojure",
            "content": "Through the labyrinth of the internet I somehow ended up watching Rich Hickey, the creator of Clojure. Now and then the stars align and I navigate Youtube, which I found to be badly sorted and organized. . It’s a great talk and it made me want to try out Clojure. My goal was to learn Swift, but, …, procrastination happened? I did a dozen or so exercises on Hackerrank. . One of the exercises was to reverse a list, without using the built-in function. Here it started to be weird. . My first thought was to use the reduce function where you walk through the list and built up a new result. conj[oin] is used to return a new collection with the element added. . Let’s skip reading the documentation completely of course :) . Doesn’t work: . (fn [list] (reduce conj [] lst) ) . Works: . (fn [list] (reduce conj () lst) ) . There is a difference based on the type () is a list, [] is a vector. And, as is stated clearly in the documentation conj works differently for each datatype: . For lists it adds at the end, the underlying implementation is a singly-linked list. So, makes sense. | For vectors it adds at the beginning | . Probably the best option is to use sequences and use cons. But how that would exactly work…a quick try in the editor of Hackerrank just gave me stack traces that my function definition was wrong. Copy-pasting an example from the Clojure docs and the problem persisted. .",
            "url": "https://grjzwaan.github.io/website/2020/02/07/watching-rick-hickey-and-trying-out-clojure.html",
            "relUrl": "/2020/02/07/watching-rick-hickey-and-trying-out-clojure.html",
            "date": " • Feb 7, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://grjzwaan.github.io/website/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Back to Hugo ",
            "content": "Last year I experimented with Sapper Sapper to create a static blog, but I’ve already switched back to Hugo. Mainly because I’ve done the experiment and learned from it. . Writing a post had little speedbumps and the result was no posts since october. At least I know where the line is for me. .",
            "url": "https://grjzwaan.github.io/website/2020/01/09/back-to-hugo.html",
            "relUrl": "/2020/01/09/back-to-hugo.html",
            "date": " • Jan 9, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Import fun with Parcel",
            "content": "Today I was having fun with Parcel and generating a bundle for NodeJS. Very convenient, only importing seemed weird. Some imports were ‘successful’ in the sense that both Parcel and NodeJS could resolve it, but the import was {default: {}}. Hmmm. . I also write my thoughts on bundlers I used. Depending on your standards it might or might not be a review. . Bundling . A JavaScript bundler is a tool that puts your code and all its dependencies together in one JavaScript file. . There are many reasons you want this. One of the main reasons is if you develop a client side Javascript library. You actually need to serve all your Javascript and cannot rely on the client to have dependencies installed. . Further, most of these bundlers transpile sane Javascript to insane Javascript that is backwards compatible, and minify it. Notice that sane is relative here. . If you’re stumped by these bundlers and why it seems a big deal, you’re probably programming in Go or Java where the compiler actually makes bundles for you. . For NodeJS backend applications you could rely on the package information and get the dependencies when deploying or include them in your Docker image. But I do not like that. . Even if you’re meticulous in pinning exact versions of your dependencies other could forget to update version numbers. Or, pull their packages from NPM and all your deployments/builds fail. . You argue that I should not be so cynical. Ok, I hope you at least stop pulling dependencies during deployment, but I’ll go with it. . It’s also wasteful. You’re pulling huge amounts of dependencies and most likely you’re only using a small fraction. For me it’s no exception to have 50-100mb of modules but the compiled Javascript file is ~20kb. You can make deployment much faster and it’s self-contained. . Bundlers . I’ve used webpack, Rollup and Parcel. Webpack feels like making art with spaghetti and glue. It’s about the process, not the result and only fun if you’re not cleaning it up. I’m not biased against spaghetti and glue, but rather not have them in my code. . Rollup was pretty nice to use and I started using it because of Sapper and Svelte. Support for NodeJS bundles is lacking and Node Addons are not supported. I tried to make my own plugin for this but…one hour of weird errors and I bailed. Also because I seemed to include many plugins to make it work for NodeJS. . Parcel was working within 5 minutes and got me a nice NodeJS bundle, including the binaries in a Node Addon. Add a nice code generator and we’re good to go! Or not. One weird error got my stumped. . Consider two imports of files with special characters: . import * as route_1 from (&#39;./routes/a/b/c/[slug].js&#39;) import * as route_2 from (&#39;./routes/a/b/c/&lt;slug&gt;.js&#39;) . The imports resolve and, yes, both files really, really, really exist. . Normally this works fine, but Parcel does something with it. The imports resulted in: . route_1 = {default: {}} route_2 = {get: [AsyncFunction: get], post: [AsyncFunction: post] } } . Huh. . I did find out what the underlying issue is (probably some regex stuff in imports), but even when escaping the square brackets it did not work. The point brackets worked, so I consider it solved. .",
            "url": "https://grjzwaan.github.io/website/2019/10/28/import-fun-with-parcel.html",
            "relUrl": "/2019/10/28/import-fun-with-parcel.html",
            "date": " • Oct 28, 2019"
        }
        
    
  
    
        ,"post9": {
            "title": "Experiment: Blog with Sapper",
            "content": "This blog now runs on Sapper. The experiment succeeded but I do miss some quality of life functionality of Hugo. . Why change? . This blog used to be a very simple static website that was generated by Hugo from some Markdown files. It’s very convenient to work and I automatically deployed new versions whenever I pushed changes to the repository. . Now, if life was easy why would I change? Because playing with Sapper is fun, specifically building a front end with the underlying framework Svelte is lots of fun. . Svelte and Sapper . Svelte is in the same category as React and Vue. It’s a framework to build a front end and stay sane. Building an interactive website with vanilla Javascript usually makes me want to cry. . I’ve worked with React and Vue before and although it was quite smooth and the documentation is perfect, I always felt I type lots of code but it doesn’t do much. Both frameworks were getting in the way and it felt like magic sprinkled with other peoples components. Ugh. Getting an autocomplete to work where I needed not solution x but x’ was a horrible few hours. . Svelte felt different. I could write code as I wanted to and Svelte would compile vanilla Javascript to Javascript that interacted with the DOM. It feels great! As a test I wrote a pixel editor that could import files and drag and drop…from scratch. It felt wonderful and very productive. . So far my love story with Svelte. . Sapper is like Next.js but then with Svelte. Normally I build lots of stuff in Python but this tempted me to build applications with Sapper. . I still have to get used to NodeJS libraries and NPM compared to Python. Packages for Python feel complete and robust. In Javascript land…ugh…people really stack lots and lots of libraries on top of each other. It cannot be good if there is a package left-pad that puts the Javascript world in chaos as it’s pulled from NPM. . But Sapper tempts me. . Sapper export . Sapper has a command to export the application as a static website. It does so by sniffing out the calls to the server side and links and storing the results. . Seems pretty good, but there is no official support for Markdown, so you need to do some work yourself. I used the official website, and two repositories as a starting point to glean how they made it work: David’s blog and from a repository of Maxi Ferreira. . The main idea is to find .md files and put those in a data structure so that a webservice can serve the JSON (with raw HTML for the .md documents) to the client side application. . In the examples the .md files were in a single directory and they didn’t use images. Currently images should be in the static folder. The workflow is then to first upload images, and then refer to them from your .md file. Awkward. . Goal . The goal is to support the following directory structure: . /posts/2019/01/09/dogs.md /posts/2019/11/10/fishes/index.md /posts/2019/11/10/fishes/happy-fish.png /posts/2019/11/10/fishes/sad-fish.png . The /posts/2019/11/10/fishes/index.md document refers to happy-fish.png and sad-fish.png with a relative path. Your favorite editor can then give nice previews. . I couldn’t make it work with Sapper to have an arbitrary amount of /’s in the URL, so I made due with - instead. . The slugs in the URL should be: . vanderzwaan.dev/blog/2019-01-09-dogs vanderzwaan.dev/blog/2019-11-10-fishes . The images should be reachable with urls: . 2019-11-10-fishes/happy-fish.png 2019-11-10-fishes/sad-fish.png . Find all Markdown files . Finding the .md files should be easy, something like this will do: . const locations = glob.sync(`${POSTS_DIR}/**/*.md`); export const posts = locations.map( loc =&gt; getPost(loc)).map(post =&gt; parsePost(post)); . There was a bit of logic to map file names to slugs: a/b/c/index.md to a-b-c and a/doc.md to a-doc. Nothing terribly complicated. . Create an endpoint /blog/[slug]/[img] . We need to be able to serve the images in the blogpost so let’s create an endpoint that returns a certain image for a post. But then we also need to have a list of images and their locations. . For each post we also find the images in the same folder and store them: . const attachments = new Map(); glob.sync(`${base}/*.png`) .map(f =&gt; getFileInformation(f, POSTS_DIR)) .forEach(attachment =&gt; { attachments.set(attachment.filename, attachment); }); . The service is a standard Express server route that serves an image. . Add images to sapper export . It seems as if we should be done, but I found out that sapper export only follows links and not the references. . This required some code changes to Sapper export to also follow href attributes and a new mode to read files as images are in binary. . I should probably make a pull request for this, but currently the code is hacky. . #Result . I’m pretty happy with the result, but I do miss the following nice things from Hugo: . Scaffolding | It watches the .md files, Sapper does not (so manual recompile) | .",
            "url": "https://grjzwaan.github.io/website/2019/10/14/experiment-blog-with-sapper.html",
            "relUrl": "/2019/10/14/experiment-blog-with-sapper.html",
            "date": " • Oct 14, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Starlette: A tale that was silently swallowed by uvicorns.",
            "content": "Imagine the following bugreport of your Starlette application: . Calling your API results 30% of the time in an error and 70% in correct behaviour. . and you know that these calls are time independent and should either always work or never work. Locally you cannot reproduce it, but the error can be traced to a datastructure being empty…which is filled during startup. . This is the offending code: . @app.on_event(&#39;startup&#39;) async def startup(): logger.info(&quot;Executing the startup phase...&quot;) create_datastructure() logger.info(&#39;Ready to go!&#39;) . Locally you can never let create_datastructure() fail and it doesn’t make any external calls (it reads a local file and processes it). . Going deeper: in production there were 4 workers and locally only 1, and 30% is suspiciously close to a quarter. . Turns out that errors during a startup hook are silently swallowed by Uvicorn and the worker will still start. Add to that unexplicable behaviours of AWS Elastic Beanstalk to randomly insert chaos during startup. . The annoying part is that AWS Elastic Beanstalk is very slow and the deployment (in my experience) is frail and prone to fail. It all takes quite a while and you need to do yet another deployment… . So, this is the new code to at least detect that AWS Elastic Beanstalk causes some error that Uvicorn than kindly sweeps under the rug. Now, it’ll fail, as it should. . @app.on_event(&#39;startup&#39;) async def startup(): try: logger.info(&quot;Executing the startup phase...&quot;) create_datastructure() logger.info(&#39;Ready to go!&#39;) except Exception as e: logger.error(str(e)) raise e .",
            "url": "https://grjzwaan.github.io/website/2019/08/13/starlette-a-tale-that-was-silently-swallowed-by-unicorns.html",
            "relUrl": "/2019/08/13/starlette-a-tale-that-was-silently-swallowed-by-unicorns.html",
            "date": " • Aug 13, 2019"
        }
        
    
  
    
        ,"post11": {
            "title": "Starlette and Socketio Improvements",
            "content": "This is a followup of the previous article on using Starlette together with Python-SocketIO and background processes. . I’ve made some improvements, especially to handle SIGINT (ctrl+c) properly. Additionally, I wanted to start background processes without waiting for a client to connect (this is a solution I saw online). . The core problem was that all async tasks should be on the same loop. The solution took some digging around uvicorn internals, but the following worked: . Get the Uvicorn server as an awaitable; | Join the awaitable with your background tasks and return when the first completes | Run the composed application. | . This properly responds to SIGINT and all processes start without waiting for outside interaction. . Background tasks are more like workers here. One-off tasks fall in two categories: . Startup or shutdown: Use Starlette hooks for startup and shutdown to handle work there; | Based on interactions from outside: Just call tasks when an API is called. | . import logging import uvicorn from app import app import asyncio from uvicorn.loops.uvloop import uvloop_setup logging.basicConfig( level=logging.INFO, format=&quot;%(asctime)-15s %(levelname)-8s %(message)s&quot; ) def uvicorn_task(): &quot;&quot;&quot; Returns running the app in uvicorn as an awaitable to join the main asyncio loop. &quot;&quot;&quot; config = uvicorn.Config(app, host=&#39;0.0.0.0&#39;, port=8000) server = uvicorn.Server(config) return server.serve() async def main(app): &quot;&quot;&quot; Joins unicorn together with background tasks defined in the app. &quot;&quot;&quot; # Make the list with awaitables aws = [uvicorn_task(), *app.background_tasks()] # Run and return when the first completes or is cancelled await asyncio.wait(aws, return_when=asyncio.FIRST_COMPLETED) if __name__ == &#39;__main__&#39;: # Set up the loop uvloop_setup() loop = asyncio.get_event_loop() # Run the main loop asyncio.run(main(app)) .",
            "url": "https://grjzwaan.github.io/website/2019/06/13/starlette-and-socketio-improvements.html",
            "relUrl": "/2019/06/13/starlette-and-socketio-improvements.html",
            "date": " • Jun 13, 2019"
        }
        
    
  
    
        ,"post12": {
            "title": "HTTP Redirects and Funny behaviour",
            "content": "Recently I had a weird problem reported of an application I made: . When I submit a form it sometimes fails and I get an empty form again. But only sometimes. . It took quite a while to find out what actually happened. What made it hard to debug (but finally gave me the answer) is that the posted information didn’t end up in the server. So either the browser or some middleware was messing it up. . Locally I never had any problems. It always worked. But the client was using confidential information in their tests. This turned out a red herring. . The solution was to look at the requests made by the client: whenever it went wrong, there was a 302 redirect to authenticate again. Turns out if a POST request results in a redirect, it will be a GET request, essentially all POST information gets lost See Stack Overflow. After authenticating Keycloak redirected back, to an empty form. For the client, who didn’t see the redirect, it was as if the server just lost their input. . For working with OIDC I noticed that the OIDC library only redirects if it cannot refresh the token via a direct HTTP call to the server. Additionally, I was using multiple workers for the Flask application without distributed storage of OIDC information. . So the solution was: . Let people be logged in longer (internal application, so that’s fine); | Create a simple storage to share information between workers, so refreshes go via an HTTP call not a redirect. | .",
            "url": "https://grjzwaan.github.io/website/2019/06/13/http-redirects-and-funny-behaviour.html",
            "relUrl": "/2019/06/13/http-redirects-and-funny-behaviour.html",
            "date": " • Jun 13, 2019"
        }
        
    
  
    
        ,"post13": {
            "title": "Decimals and DynamoDB",
            "content": "A short note on DynamoDB of AWS and how it suprisingly gives Decimals when you extract records. And forced me to write ducktape-code. . The story . DynamoDB implicitely converts integers to decimals. Decimals cause some problems in Python code since it is not a basic type. For example, json.dumps() doesn’t work anymore. . You put a Python datastructure with lists and dictionairies into DynamoDB with strings and integers. | DynamoDB converts and stores the datastructure | You load an entry from DynamoDB | …it suddenly contains Decimals instead of integers | …and json.dumps() crashes (among others) | The ‘solution’ . I now simply convert decimals back to float and int. The alternative of storing the object as a string (convert to JSON) I dislike. Figuring out how to configure DynamoDB…I couldn’t find a decent way within half an hour. I did find a discussion on a feature request to disable decimals and/or find some sane way to work with it, but no solutions. . So I wrote a little function to convert a dictionary: . def convert_decimal(dictionary): &quot;&quot;&quot; Converts decimals to float and int. &quot;&quot;&quot; for key in dictionary.keys(): value = dictionairy[key] if isinstance(value, Decimal): if v % 1 == 0: dictionary[key] = int(value) else: dictionary[key] = float(value) return dictionary .",
            "url": "https://grjzwaan.github.io/website/2019/05/02/decimals-and-dynamodb.html",
            "relUrl": "/2019/05/02/decimals-and-dynamodb.html",
            "date": " • May 2, 2019"
        }
        
    
  
    
        ,"post14": {
            "title": "Flask Pdf Download",
            "content": "This is a short note on getting PDF downloads working on Flask. . The goal is a button with ‘Download as PDF’: . Generate an HTML page | Convert his page to a PDF | Download the PDF while staying on the same page | . This seemed easy: just use pdfkit, get the correct dependencies and go. It turns out there were some hiccups for which I needed to combine several answers. . wkhtml did not work headless, I needed to patch it | PDFkit examples and the API ask for a filename, I did not want to store the PDF | PDFkit returns bytes and not a fileobject that Flask expects | For a few minutes I forgot about caching headers. I always want to generate a PDF on the current version | . Getting PDFkit to run on a Docker image . I used the following code to get it working. It uses apt-get to get wkhtmltopdf and its dependencies. Then, I patched wkhtmltopdf to make it work headless. . RUN apt-get update RUN apt-get install -y wkhtmltopdf RUN wget -nv https://downloads.wkhtmltopdf.org/0.12/0.12.5/wkhtmltox_0.12.5-1.stretch_amd64.deb RUN apt install -y ./wkhtmltox_0.12.5-1.stretch_amd64.deb RUN pip install pdfkit . For some reason (there are more people talking about this issue) the headless part does not work out-of-the-box due to some upstream problem of a dependency. . Generate the PDF . import pdfkit # ...Import other Flask stuff # Render the HTML print_html = render_template(&#39;print.html&#39;) # Convert the HTML to PDF, as target filename give &#39;False&#39; pdf = pdfkit.from_string(print_html, False) # Convert the bytes to a file(like) file = io.BytesIO(pdf) # Optional: add a timestamp to the generated file. created_on = current_time_local().strftime(&#39;%Y-%m-%d %H:%M:%S&#39;) filename = f&quot;Filename ({created_on})&quot; # Output to the browser return send_file(file, attachment_filename=filename, mimetype=&#39;application/pdf&#39;, # Give this argument to let the user stay on the current page as_attachment=True, # Set a low cache timeout cache_timeout=-1) .",
            "url": "https://grjzwaan.github.io/website/2019/04/24/flask-pdf-download.html",
            "relUrl": "/2019/04/24/flask-pdf-download.html",
            "date": " • Apr 24, 2019"
        }
        
    
  
    
        ,"post15": {
            "title": "Python Partial",
            "content": "This is a short note on the Python function partial. . Partials are very common in functional languages such as Haskell and Elm. . Functional language . Suppose you need a function to color a line, it would map the position on the line (ranging from 0 to 1) to a RGB color like so (for convenience I noted the tuple as RGB instead of (Int, Int, Int)): . color :: Position -&gt; RGB . But we do not want to define a function for, say, all gradients: . blue_green :: Position -&gt; RGB blue_green p = (0, p * 255, (1 - p) * 255) + (0, (1 - p) * 255, p * 255) . We can now define a function: . gradient :: RGB -&gt; RGB -&gt; Position -&gt; RGB gradient l r p = (1 - p) * l + p * r . However we’re in a bit of a pickle since our line coloring expects a function that maps positions to RGB. Functional languages allow is to simply only pass the first two arguments: . color_function = gradient (0, 255, 50) (50, 0, 100) . This yields a function that maps positions to RGB and the functionality does not need to know how it was constructed. . Python . Python has the partial function to do this. . # Target signature and behaviour: def color (position): return (R, G, B) # Gradient coloring function def gradient(p, left=(0, 0, 0), right=(255, 255, 255)): return tuple((1 - p) * left[i] + p * right[i] for i in range(3)) # Now get a blue-green coloring function blue_green = partial(gradient, left=(0, 0, 255), right=(0, 255, 0)) . Alternatively: . # Target signature and behaviour: def color (position): return (R, G, B) # Gradient coloring function def gradient(left, right, p): return tuple((1 - p) * left[i] + p * right[i] for i in range(3)) # Now get a blue-green coloring function blue_green = partial(gradient, (0, 0, 255), (0, 255, 0)) .",
            "url": "https://grjzwaan.github.io/website/2019/04/16/python-partial.html",
            "relUrl": "/2019/04/16/python-partial.html",
            "date": " • Apr 16, 2019"
        }
        
    
  
    
        ,"post16": {
            "title": "Starlette and Socketio",
            "content": "A short note on how to use Starlette together with Python-SocketIO. For a DIY project I want to run a single thread process to control a wake-up light (among other things). . Starlette . Starlette is basically an asynchronous version on Flask, which are both web frameworks. Personally I use Flask quite often and like the philosophy and resulting code. . Starlette seems to take inspiration from Flask and improves on speed. Additionaly there are some nice quality-of-life improvements (Websocktes, GraphQL). The asynchrounous part gives must easier in-process background tasks, for example sending an e-mail. . In their own words: . Starlette is a lightweight ASGI framework/toolkit, which is ideal for building high performance asyncio services. . SocketIO (and Python-SocketIO) . Socket.IO is a library on top of websockets . Python-SocketIO is a Python library that enables you to work with socket.io in Python. The name is pretty descriptive: . This projects implements Socket.IO clients and servers that can run standalone or integrated with a variety of Python web frameworks. . The problem . I wanted the following things: . Starlette with a REST API; | SocketIO (through Python-SocketIO) for realtime streams; | A background task that periodially streams the current information in the system. | . Additionally I wanted to have it in a single thread, and no heavy extra libraries. Such as distributed task queues (Celery) which then require other moving parts. . Part of the reason is that I have a single state in memory of some hardware components. It being a single-threaded async application makes it very easy to argue about updating the state and reading the state. . I ran into some issues when wanting to combine Starlette+Python-SocketIO+background tasks. Starlette runs on Uvicorn and the current way how Python-SocketIO hooks into the async loop was not working anymore. . After some trial and error I got it working: . import logging import asyncio import uvicorn from uvicorn.loops.uvloop import uvloop_setup from starlette.applications import Starlette from starlette.responses import JSONResponse import socketio # Set some basic logging logging.basicConfig( level=2, format=&quot;%(asctime)-15s %(levelname)-8s %(message)s&quot; ) # Create a basic app sio = socketio.AsyncServer(async_mode=&#39;asgi&#39;) star_app = Starlette(debug=True) app = socketio.ASGIApp(sio, star_app) @star_app.route(&#39;/&#39;) async def homepage(request): return JSONResponse({&#39;hello&#39;: &#39;world&#39;}) @sio.on(&#39;connect&#39;) async def connect(sid, environ): logging.info(f&quot;connect {sid}&quot;) @sio.on(&#39;message&#39;) async def message(sid, data): logging.info(f&quot;message {data}&quot;) # await device.set(data) @sio.on(&#39;disconnect&#39;) async def disconnect(sid): logging.info(f&#39;disconnect {sid}&#39;) # Set up the event loop async def start_background_tasks(): while True: logging.info(f&quot;Background tasks that ticks every 10s.&quot;) await sio.sleep(10.0) async def start_uvicorn(): uvicorn.run(app, host=&#39;0.0.0.0&#39;, port=8000) async def main(loop): bg_task = loop.create_task(start_background_tasks()) uv_task = loop.create_task(start_uvicorn()) await asyncio.wait([bg_task, uv_task]) if __name__ == &#39;__main__&#39;: uvloop_setup() loop = asyncio.get_event_loop() loop.run_until_complete(main(loop)) loop.close() . Perhaps there are other people running into the same issue and I can save them some time. .",
            "url": "https://grjzwaan.github.io/website/2019/04/13/starlette-and-socketio.html",
            "relUrl": "/2019/04/13/starlette-and-socketio.html",
            "date": " • Apr 13, 2019"
        }
        
    
  
    
        ,"post17": {
            "title": "Posture of cats: machine learning with fast.ai",
            "content": "During a spare hour I decided to see how fast I could prototype something with the fast.ai library. The library is impressive, I can’t say otherwise. Very quickly I got a working prototype. The result was a fairly decent model to recognize the posture of a cat. . Fast.ai library . Recently I’ve decided to take a look at fast.ai, their course and their library. The best way to do this is to try something and it’s very likely you’ll end up with a cat-related topic. With my desk oriented towards the spot my cat was chilling, I decided to take the library for a spin and recognize cat postures. . To make the post self-contained I’ll note the snippets of code needed. As you’ll see it’s actually very little code - and every line is clear on what it does. . Note: Most of the code was copied from the example notebook in the course of fast.ai. . from fastai.vision import * from fastai.metrics import error_rate . The postures . I picked the first four postures that came to mind: . Lounging | Curled up | Sitting | Walking | . . Getting the data . There are some pictures of my cat but not sufficient. He is very lazy and is predominantly curled up. In the course of fast.ai they discussed the option to just use Google searches to get a dataset quickly. I have done this before, but they had some nice helpers to really make it a smooth experience: . 1) Do a Google Image search yourself. For example, search for “cats curled up” . 2) Run a JavaScript script they supply and obtain a file with urls . urls = Array.from(document.querySelectorAll(&#39;.rg_di .rg_meta&#39;)).map(el=&gt;JSON.parse(el.textContent).ou); window.open(&#39;data:text/csv;charset=utf-8,&#39; + escape(urls.join(&#39; n&#39;))); . 3) Run a function from their library to download and verify the images . download_images(&#39;path/urls_cats.csv&#39;, &#39;path/where/to/download/images&#39;, max_pics=200) verify_images(&#39;path/where/to/download/images&#39;, delete=True, max_size=500) . 4) Create a dataset . np.random.seed(42) # Set a fixed seed to always get the same train-validation split data = ImageDataBunch.from_folder(&quot;path/to/images&quot;, train=&quot;.&quot;, valid_pct=0.2, ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats) . Training the neural network . Training the neural network is actually very simple . 5) Create the neural network: . learn = cnn_learner(data, models.resnet50, metrics=error_rate) . 6) Find a a good learning rate: . learn.lr_find(start_lr=1e-4) learn.recorder.plot() . 7) Train the neural network: . learn.fit_one_cycle(12, max_lr=2e-2) . There are some additional steps you can take to further finetune the model, but notice how easy it is? . Performance . The performance was actually quite decent: an error rate of 17%. Especially if you realize that the the distinction between classes is fuzzy and can be subtle. The images that the google search returned quite often confused lounging with curled up and sitting with lounging. . Even I’m not totally clear on the distinction between lounging and curled up in some cases :) . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . . Let’s plot the images the model was the most confused about, and highlight the areas that the model was focused on: . interp.plot_top_losses(9, figsize=(15,11)) . . Improvements . As you can see in the top losses, the samples contain some images that are no good: multiple cats or to far zoomed in. The easiest thing to do would be to get a better dataset and make a clear distinction between the classes. . How does it work . The cool thing fast.ai did in their course is to encode as many best practices in the library as they can. This means that you don’t start with a neural network from scratch: you take a network architecture that is tested in practices, is pretrained and you get sensible defaults. . In my case I used ResNet50 and then fine-tuned it with the cat data. This means you’re getting a lot for free! .",
            "url": "https://grjzwaan.github.io/website/2019/04/10/cature.html",
            "relUrl": "/2019/04/10/cature.html",
            "date": " • Apr 10, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://grjzwaan.github.io/website/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://grjzwaan.github.io/website/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}